Day 1 of #365DaysofResearchPapers

# The power of quantum neural networks
Amira Abbas, David Sutter, Christa Zoufal, Aur√©lien Lucchi, Alessio Figalli, Stefan Woerner

* Fault-tolerant quantum computers offer the promise of dramatically improving machine learning through speed-ups in computation or improved model scalability. 
* In the near-term, however, the benefits of quantum machine learning are not so clear. 
* Understanding expressibility and trainability of quantum models-and quantum neural networks in particular-requires further investigation.
* In this work, we use tools from information geometry to define a notion of expressibility for quantum and classical models.
* The effective dimension, which depends on the Fisher information, is used to prove a novel generalisation bound and establish a robust measure of expressibility.
* We show that quantum neural networks are able to achieve a significantly better effective dimension than comparable classical neural networks.
* To then assess the trainability of quantum models, we connect the Fisher information spectrum to barren plateaus, the problem of vanishing gradients.
* Importantly, certain quantum neural networks can show resilience to this phenomenon and train faster than classical models due to their favourable optimisation landscapes, captured by a more evenly spread Fisher information spectrum.
* Our work is the first to demonstrate that well-designed quantum neural networks offer an advantage over classical neural networks through a higher effective dimension and faster training ability, which we verify on real quantum hardware.

Arxiv Link: https://arxiv.org/abs/2011.00027

## Content 

- Introduction
- Quantum Neural Networks
- Information geometry, effective dimension, and trainability of quantum neural networks
  - The Fisher information
  - The effective dimension
  - Generalisation error bounds
  - The Fisher spectrum and the barren plateau phenomenon
- Numerical experiments and results
  - The Fisher information spectrum
  - Capacity analysis
  - Trainability
-Conclusion

- A Details of the quantum models
  - A.1 Specific feature maps
  - A.2 The variational form
- B Properties of the effective dimension
  - B.1 Proof of Theorem 3.2
  - B.2 Generalisation ability of the effective dimension
  - B.3 Effective dimension converges to maximal rank of Fisher information matrix
  - B.4 A geometric depiction of the effective dimension
  - B.5 Removing the rank constraint via discretisation
- C Numerical experiments
  - C.1 Sensitivity analysis for the effective dimension
  - C.2 The Fisher information spectra for varying model size
  - C.3 Training the models using a simulator
  - C.4 Training the quantum neural network on real hardware
  - 












